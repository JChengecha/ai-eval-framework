{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Task Evaluation - Failure Analysis Framework\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates a comprehensive failure analysis framework for AI agent performance evaluation. The framework identifies patterns, root causes, and statistical anomalies across multiple dimensions.\n",
    "\n",
    "**Key Capabilities:**\n",
    "- Multi-dimensional failure pattern detection\n",
    "- Statistical significance testing\n",
    "- Root cause hypothesis generation\n",
    "- Interactive visualizations\n",
    "- Actionable recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_generator import AIEvaluationDataGenerator\n",
    "from failure_analyzer import FailureAnalyzer\n",
    "from visualizer import FailureVisualizer\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Evaluation Data\n",
    "\n",
    "We'll generate realistic AI task evaluation data with built-in failure patterns that simulate real-world scenarios in finance domain tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate dataset\n",
    "generator = AIEvaluationDataGenerator()\n",
    "df = generator.generate_dataset(n_samples=1000)\n",
    "generator.save_dataset(df, filepath='../data/ai_evaluations.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quick overview\n",
    "print(\"Dataset Summary:\")\n",
    "print(f\"Total Tasks: {len(df):,}\")\n",
    "print(f\"Success Rate: {df['success'].mean():.2%}\")\n",
    "print(f\"Failure Rate: {(1-df['success'].mean()):.2%}\")\n",
    "print(f\"\\nScore Statistics:\")\n",
    "print(df['score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Overall Performance Metrics\n",
    "\n",
    "Start with high-level metrics to understand overall AI agent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "analyzer = FailureAnalyzer(df)\n",
    "metrics = analyzer.overall_metrics()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"OVERALL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float) and 0 <= value <= 1:\n",
    "        print(f\"{key:.<30} {value:.2%}\")\n",
    "    elif isinstance(value, float):\n",
    "        print(f\"{key:.<30} {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key:.<30} {value:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Dimension Analysis\n",
    "\n",
    "Analyze failure rates across individual dimensions to identify problematic areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# File Type Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAILURE ANALYSIS BY FILE TYPE\")\n",
    "print(\"=\"*60)\n",
    "file_type_analysis = analyzer.failure_by_dimension('file_type')\n",
    "print(file_type_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Task Type Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAILURE ANALYSIS BY TASK TYPE\")\n",
    "print(\"=\"*60)\n",
    "task_analysis = analyzer.failure_by_dimension('task_type')\n",
    "print(task_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Finance Domain Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAILURE ANALYSIS BY FINANCE DOMAIN\")\n",
    "print(\"=\"*60)\n",
    "domain_analysis = analyzer.failure_by_dimension('finance_domain')\n",
    "print(domain_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Agent Performance Comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAILURE ANALYSIS BY AI AGENT\")\n",
    "print(\"=\"*60)\n",
    "agent_analysis = analyzer.failure_by_dimension('agent')\n",
    "print(agent_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Dimensional Analysis\n",
    "\n",
    "Compare failure patterns across all dimensions simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "multi_dim = analyzer.multidimensional_analysis()\n",
    "print(\"\\nTop 15 Highest Risk Categories (Across All Dimensions):\")\n",
    "print(multi_dim.nlargest(15, 'failure_rate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Significance Testing\n",
    "\n",
    "Test whether observed failure rate differences are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "dimensions = ['task_type', 'file_type', 'finance_domain', 'evaluation_criterion', 'agent']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTS (Chi-Square)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Dimension':<25} {'Chi2':>12} {'P-Value':>12} {'Significant':>15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "sig_tests = []\n",
    "for dim in dimensions:\n",
    "    test = analyzer.statistical_significance_test(dim)\n",
    "    sig_tests.append(test)\n",
    "    sig_marker = \"✓ YES\" if test['significant'] else \"✗ No\"\n",
    "    print(f\"{test['dimension']:<25} {test['chi2_statistic']:>12.2f} {test['p_value']:>12.4f} {sig_marker:>15}\")\n",
    "\n",
    "sig_df = pd.DataFrame(sig_tests)\n",
    "print(f\"\\nSignificant dimensions: {sig_df['significant'].sum()}/{len(sig_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. High-Risk Segment Identification\n",
    "\n",
    "Identify specific segments with unacceptably high failure rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "high_risk = analyzer.identify_high_risk_segments(threshold=0.35)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HIGH-RISK SEGMENTS (Failure Rate > 35%)\")\n",
    "print(\"=\"*70)\n",
    "print(high_risk.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Error Type Distribution\n",
    "\n",
    "Analyze what types of errors are most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "error_dist = analyzer.error_type_distribution()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ERROR TYPE DISTRIBUTION\")\n",
    "print(\"=\"*50)\n",
    "print(error_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis\n",
    "\n",
    "Examine relationships between numerical features and success rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "correlations = analyzer.correlation_analysis()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS: Numerical Features vs Success\")\n",
    "print(\"=\"*80)\n",
    "print(correlations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Temporal Analysis\n",
    "\n",
    "Track how performance changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "temporal = analyzer.temporal_analysis()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEMPORAL PERFORMANCE TRENDS\")\n",
    "print(\"=\"*70)\n",
    "print(temporal.head(10))\n",
    "print(\"\\n...\")\n",
    "print(temporal.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Root Cause Hypotheses\n",
    "\n",
    "Generate data-driven hypotheses about failure root causes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "hypotheses = analyzer.root_cause_hypothesis()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROOT CAUSE HYPOTHESES & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, hyp in enumerate(hypotheses, 1):\n",
    "    print(f\"\\n[HYPOTHESIS {i}]\")\n",
    "    print(f\"Dimension: {hyp['dimension']}\")\n",
    "    print(f\"Hypothesis: {hyp['hypothesis']}\")\n",
    "    print(f\"Evidence: {hyp['evidence']}\")\n",
    "    print(f\"Worst Performer: {hyp['worst_performer']} (Failure Rate: {hyp['failure_rate']:.1%})\")\n",
    "    print(f\"Recommendation: {hyp['recommendation']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualizations\n",
    "\n",
    "Create comprehensive visual analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "viz = FailureVisualizer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Multi-dimensional dashboard\n",
    "viz.plot_multidimensional_summary(output_path='../outputs/dashboard.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# File type analysis\n",
    "viz.plot_failure_rates_by_dimension('file_type', \n",
    "                                    output_path='../outputs/file_type_analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Task type analysis\n",
    "viz.plot_failure_rates_by_dimension('task_type',\n",
    "                                    output_path='../outputs/task_type_analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Interaction effects: Task Type vs File Type\n",
    "viz.plot_interaction_heatmap('task_type', 'file_type',\n",
    "                            output_path='../outputs/interaction_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Error type distribution\n",
    "viz.plot_error_type_distribution(output_path='../outputs/error_types.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Score distributions\n",
    "viz.plot_score_distributions(output_path='../outputs/score_distributions.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Temporal trends\n",
    "viz.plot_temporal_trends(output_path='../outputs/temporal_trends.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Findings Summary\n",
    "\n",
    "Let's compile the most actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"#\" + \" \"*30 + \"KEY FINDINGS\" + \" \"*36 + \"#\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "print(\"\\n[1] OVERALL PERFORMANCE\")\n",
    "print(f\"    - Success Rate: {metrics['success_rate']:.1%}\")\n",
    "print(f\"    - Average Score: {metrics['avg_score']:.1f}/100\")\n",
    "print(f\"    - Total Tasks Evaluated: {metrics['total_tasks']:,}\")\n",
    "\n",
    "print(\"\\n[2] HIGHEST RISK AREAS\")\n",
    "top_risks = high_risk.head(3)\n",
    "for idx, row in top_risks.iterrows():\n",
    "    print(f\"    - {row['dimension']}: {row['category']} (Failure Rate: {row['failure_rate']:.1%})\")\n",
    "\n",
    "print(\"\\n[3] MOST COMMON ERROR TYPES\")\n",
    "top_errors = error_dist.head(3)\n",
    "for error_type, data in top_errors.iterrows():\n",
    "    print(f\"    - {error_type}: {data['count']} occurrences ({data['percentage']:.1f}%)\")\n",
    "\n",
    "print(\"\\n[4] STATISTICALLY SIGNIFICANT FACTORS\")\n",
    "sig_dims = [t['dimension'] for t in hypotheses]\n",
    "for dim in sig_dims:\n",
    "    print(f\"    - {dim}\")\n",
    "\n",
    "print(\"\\n[5] TEMPORAL PATTERNS\")\n",
    "early_failure = temporal.head(5)['failure_rate'].mean()\n",
    "late_failure = temporal.tail(5)['failure_rate'].mean()\n",
    "trend = \"increasing\" if late_failure > early_failure else \"decreasing\"\n",
    "print(f\"    - Failure rate is {trend} over time\")\n",
    "print(f\"    - Early period: {early_failure:.1%} | Late period: {late_failure:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This framework provides:\n",
    "- **Multi-dimensional failure analysis** across task types, file formats, domains, and agents\n",
    "- **Statistical validation** of observed patterns using hypothesis testing\n",
    "- **Root cause identification** with data-driven recommendations\n",
    "- **Visual analytics** for stakeholder communication\n",
    "- **Actionable insights** for improving AI evaluation frameworks\n",
    "\n",
    "The analysis reveals systematic patterns in AI agent failures that can guide improvements in:\n",
    "- Task design and complexity management\n",
    "- File preprocessing and parsing\n",
    "- Domain-specific model training\n",
    "- Evaluation rubric clarity\n",
    "- Agent configuration optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
